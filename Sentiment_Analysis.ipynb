{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sW3myTnYFJKN"
      },
      "source": [
        "\n",
        "# Text Classification for Sentiment Analysis\n",
        "\n",
        "\n",
        "This project uses a dataset of Amazon reviews to perform sentinent analysis.\n",
        "\n",
        "## Data Preparation, Cleaning, Preprocessing\n",
        "\n",
        "We begin by preparing the dataset, loading it into Pandas and keeping only the reviews and ratings -- only these two columns will be relevant for our scope. We then turn the problem into a 3 class classification problem and select 20,000 reviews from each class and do a 80-20 split on this sample.\n",
        "\n",
        "In accordance to common practice in NLP, we perform some data cleaning which consists of:\n",
        "* Removing HTML\n",
        "* Removing multiple spaces\n",
        "* Removing URLs\n",
        "* Removing non-alphabetical characters\n",
        "* Using the `contractions` library to perform contractions.\n",
        "\n",
        "After this, we use `nltk` to do some preprocessing and remove stop words as well as lemmatize the data.\n",
        "\n",
        "## Feature Extraction\n",
        "After this, we use SKLearn to extract TFIDF features of the dataset and build the vocabulary. We then use these features as well as our ground truth 3-classes in evaluating a variety of approaches.\n",
        "\n",
        "## Perceptron\n",
        "A perceptron model is a simple model with a single layer of neurons. The input features are multipled with a set of weights and passed through a threshold function, where the perceptron algorithm is used to calibrate the weights. It only classifies linear decision boundaries.\n",
        "\n",
        "We obtain a F1 score of 65.40% on this dataset using the Perceptron approach.\n",
        "\n",
        "## SVM\n",
        "An SVM finds the best boundary/hyperplane that seperates the data into seperate classes. This should maximize maximizes the margin, which is the distance between the boundary and the closest data points from each class, also called support vectors.\n",
        "\n",
        "RBF is a type of kernel for high dimensional data and so is poly. We try both of them and report the best of them. \n",
        "\n",
        "We obtain a F1 score of 70.73% on the dataset using the RBF Kernel.\n",
        "\n",
        "## Logistic Regression\n",
        "Multinomial logistic regression applies a linear function to a set of features and applies a softmax to the data to obtain a probability distribution over K classes\n",
        "\n",
        "We obtain a F1 score of 72.94% using multinomial logistic regression with the `lbfgs` solver\n",
        "\n",
        "## Naive Bayes\n",
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). We use TFIDF to obtain a distribution of our 3 classes above.\n",
        "\n",
        "We obtain a F1 score of 71.47% using multinomial naive bayes.\n",
        "\n",
        "# Findings\n",
        "Between the SVM approach, Logistic Regression, and Naive Bayes, we get minimal improvements within our F1 scores.\n",
        "\n",
        "Logistic regression gives us our best performance with an F1 score of 72.94%. The logistic regression approach winning indicates a linear relationship between the features and classes.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgPUuzb5Ld4f"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRHH4s9JLjtF"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DFR4hXnDDjHp"
      },
      "outputs": [],
      "source": [
        "env = 'colab'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8IJOhciOuGpz",
        "outputId": "8d54b14b-48d4-41d6-e1fc-9437a2948b9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5DvqIrWQj5pe",
        "outputId": "69fd83a4-84f8-4983-e2b5-e28607831980"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yeR7I70GuGp7",
        "outputId": "a09e59ee-9667-4251-9535-50091559fb11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4OT2vhjUeJzS",
        "outputId": "b42cad24-d595-41c2-b935-1f0bd1ac21f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g1nEvrLQC53o",
        "outputId": "b818d9ec-f6c4-462a-c73c-f7adaee05f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install bs4 # in case you don't have it installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P_JaINCabAdo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bBXpClYsuGp2",
        "outputId": "a9d1d90f-0d80-4b8d-8443-a679b6950142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-20 22:37:33--  https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.153.118, 52.217.44.54, 52.216.35.64, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.153.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914070021 (872M) [application/x-gzip]\n",
            "Saving to: ‘amazon_reviews_us_Beauty_v1_00.tsv.gz’\n",
            "\n",
            "amazon_reviews_us_B 100%[===================>] 871.72M  20.7MB/s    in 24s     \n",
            "\n",
            "2023-01-20 22:37:58 (36.0 MB/s) - ‘amazon_reviews_us_Beauty_v1_00.tsv.gz’ saved [914070021/914070021]\n",
            "\n",
            "gzip: /content/amazon_reviews_us_Beauty_v1_00.tsv already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ],
      "source": [
        "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n",
        "!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n",
        "!gunzip /content/amazon_reviews_us_Beauty_v1_00.tsv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BsB5rbeyDUW7"
      },
      "outputs": [],
      "source": [
        "dataset_path = None\n",
        "if env == \"colab\":\n",
        "   dataset_path = './amazon_reviews_us_Beauty_v1_00.tsv'\n",
        "else:\n",
        "    dataset_path = './data.tsv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJWSHowuGp3"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PifBPtyquGp4"
      },
      "outputs": [],
      "source": [
        " df = pd.read_csv(dataset_path, sep='\\t', on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CUrfyM7uGp4"
      },
      "source": [
        "## Keep Reviews and Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p4UyY7ewuGp5"
      },
      "outputs": [],
      "source": [
        "# calling head() method  \n",
        "# storing in new variable \n",
        "data_top = df.head() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK_xIXsdVUkD"
      },
      "source": [
        "#### Dropping all columns except review_body and star_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ATD5o7ZGVPc_"
      },
      "outputs": [],
      "source": [
        "df.drop(df.columns.difference(['review_body', 'star_rating']), 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VYp52PCZVStn"
      },
      "outputs": [],
      "source": [
        "df.loc[df['star_rating'] == '1', 'class'] = 1\n",
        "df.loc[df['star_rating'] == '1', 'class'] = 1\n",
        "df.loc[df['star_rating'] == '3', 'class'] = 2\n",
        "df.loc[df['star_rating'] == '4', 'class'] = 3\n",
        "df.loc[df['star_rating'] == '5', 'class'] = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cFPa-D3qVQyH"
      },
      "outputs": [],
      "source": [
        "if env == 'colab':\n",
        "  df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7uGK_BxuGp5"
      },
      "source": [
        " ## We form three classes and select 20000 reviews randomly from each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iJumMqYxuGp5"
      },
      "outputs": [],
      "source": [
        "class1_sample = df.loc[df[\"class\"] == 1].sample(n = 20000)\n",
        "class2_sample = df.loc[df[\"class\"] == 2].sample(n = 20000)\n",
        "class3_sample = df.loc[df[\"class\"] == 3].sample(n = 20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xMwj9EAvXe4R"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.concat([class1_sample, class2_sample, class3_sample], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qt5wbWuGp6"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DxwcqoCTg8tw"
      },
      "outputs": [],
      "source": [
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: str(x) if type(x)==float else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EzXWaEgHu1ts",
        "outputId": "16b2d61c-13b1-44ae-daa7-0a49533cf7b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of the words before cleaning: 153.2628\n"
          ]
        }
      ],
      "source": [
        "rev_body_split = merged_df[\"review_body\"].str.split()\n",
        "\n",
        "word_lengths = rev_body_split.apply(lambda x: sum(len(i) for i in x))\n",
        "avg_pp = word_lengths.mean()\n",
        "if (env == 'colab'):\n",
        "  print(f'Average length of the words before cleaning: {avg_pp}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WuDaJiluGp7"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QgVbdFZyai0s"
      },
      "outputs": [],
      "source": [
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fA3zu_p0ampe"
      },
      "outputs": [],
      "source": [
        "# Remove HTML\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: re.sub(r'<[^<]+?>', '', x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jmC-Ng4eauBR"
      },
      "outputs": [],
      "source": [
        "# Remove URLs\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: re.sub(r'https?://\\S+', '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sGBtc7Y_hkKQ"
      },
      "outputs": [],
      "source": [
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pg3CRjeQhy_p"
      },
      "outputs": [],
      "source": [
        "# Remove extra spaces\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: re.sub(\" +\", \" \", x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dL5fI609iwD2"
      },
      "outputs": [],
      "source": [
        "import contractions\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: contractions.fix(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6etj0MEYVY-g"
      },
      "source": [
        "## Average length after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iMHmKdeuVYXZ",
        "outputId": "8bd5be05-48b9-4687-b217-ce622cd5ff6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of the words after cleaning: 145.61068333333333\n"
          ]
        }
      ],
      "source": [
        "rev_body_split_ap = merged_df[\"review_body\"].str.split()\n",
        "\n",
        "word_lengths_ap = rev_body_split_ap.apply(lambda x: sum(len(i) for i in x))\n",
        "avg_post_cleaned = word_lengths_ap.mean()\n",
        "if env == 'colab':\n",
        "  print(f'Average length of the words after cleaning: {avg_post_cleaned}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oHc7EIV2EXs2",
        "outputId": "fc6cff6f-3747-4553-a016-1065b5a06a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153.2628,145.61068333333333\n"
          ]
        }
      ],
      "source": [
        "print(f'{avg_pp},{avg_post_cleaned}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7uTQ-OFWkY0"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOFPHV6muGp7"
      },
      "source": [
        "## remove the stop words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M2SM-cefuGp8"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7mhKydluGp8"
      },
      "source": [
        "## perform lemmatization  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cLacYwKMuGp8"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "merged_df[\"review_body\"] = merged_df[\"review_body\"].apply(lambda x: lemmatizer.lemmatize(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVVznJY9leAG"
      },
      "source": [
        "### Average length of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j51FTGu6MiaG",
        "outputId": "d843d739-8620-4393-f314-5085c7f922a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of the words after preprocessing: 95.11606666666667\n"
          ]
        }
      ],
      "source": [
        "rev_body_split_ap = merged_df[\"review_body\"].str.split()\n",
        "\n",
        "word_lengths_ap = rev_body_split_ap.apply(lambda x: sum(len(i) for i in x))\n",
        "avg_processed = word_lengths_ap.mean()\n",
        "if env == 'colab':\n",
        "  print(f'Average length of the words after preprocessing: {avg_processed}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gfBzexzDE34Z",
        "outputId": "054e0919-d384-4d18-e98f-96517b350471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "145.61068333333333,95.11606666666667\n"
          ]
        }
      ],
      "source": [
        "print(f'{avg_post_cleaned},{avg_processed}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cDzXKeguGp9"
      },
      "source": [
        "# TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpYw3Q43OhPs"
      },
      "source": [
        "**TF-IDF** is used to evaluate how important a word is to a document in a collection of documents. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the collection of documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qKOr1mmguGp9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create the vectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the data (build the vocabulary)\n",
        "vectorizer.fit(merged_df[\"review_body\"] )\n",
        "\n",
        "# Transform the data into TF-IDF features\n",
        "tfidf_features = vectorizer.transform(merged_df[\"review_body\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fIlbPWnzQfl1",
        "outputId": "2e9105f2-03cd-4cbc-fd14-20bb65ae4113"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1664340000x1 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 897499 stored elements in COOrdinate format>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_features.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EMXr0yVoQftk",
        "outputId": "1e6a1130-62df-40d4-e21c-a4d1681e1477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 27739)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pev1XfQ3Qpkr",
        "outputId": "ef409cf9-fc6d-4e82-c464-420ef78ae385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = merged_df[\"class\"].values\n",
        "labels = labels[:, np.newaxis]\n",
        "labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRUZOwpePUsr"
      },
      "source": [
        "## Split data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e9ZxcECwTD9e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ekcyaWJwTQqP",
        "outputId": "f59291ae-791b-4905-a49a-ba07799684cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (48000, 27739)\n",
            "Shape of X_test: (12000, 27739)\n",
            "Shape of y_train: (48000, 1)\n",
            "Shape of y_test: (12000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Check the shapes of the resulting matrices\n",
        "if env == 'colab':\n",
        "  print(\"Shape of X_train:\", X_train.shape)\n",
        "  print(\"Shape of X_test:\", X_test.shape)\n",
        "  print(\"Shape of y_train:\", y_train.shape)\n",
        "  print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6zgJ7hruGp9"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2ELS3mk4UK9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5vxNg26wuGp9",
        "outputId": "116a802b-f3b4-49e2-a627-e10e39dc6f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "perceptron = Perceptron(random_state=0)\n",
        "\n",
        "perceptron.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "IRLUqUdzT4CG"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "y_pred = perceptron.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2nTphxRUhD3"
      },
      "source": [
        "### Precision:\n",
        "Evaluates perfomance of a classification model, specifically in cases where the goal is to reduce the amount of false positives.  It is a measure of the model's ability to make correct positive predictions\n",
        "\n",
        " We can calcuate it by:\n",
        "Precision = TP / (TP + FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-qimjne4Uysn",
        "outputId": "548f0b1e-02a4-4e6c-8eba-52f8f9eed49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision for class 0: 0.674635429117858 Class 1: 0.5787605787605787 Class 2: 0.7000481463649495\n",
            "Average Precision: 0.6541666666666667\n"
          ]
        }
      ],
      "source": [
        "precision_perceptron = precision_score(y_test, y_pred, average=None)\n",
        "if env == 'colab':\n",
        "  print(f'Precision for class 0: {precision_perceptron[0]} Class 1: {precision_perceptron[1]} Class 2: {precision_perceptron[2]}')\n",
        "precision_perceptron_avg = precision_score(y_test, y_pred, average='micro')\n",
        "if env == 'colab':\n",
        "  print(f'Average Precision: {precision_perceptron_avg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG1FKAhcV-kL"
      },
      "source": [
        "### Recall\n",
        "When the goal is to minimize the amount of false negatives, we calculate recall by:\n",
        "TP = TP / TP + FN\n",
        "\n",
        "A high recall value indicates that the model is correctly identifying most of the positive instances in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xo5P4nwfVzwo",
        "outputId": "52c4ce6f-88a9-4b1e-e258-00a4d0fa5a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall for class 0: 0.7060295221416062 Class 1: 0.5252725470763132 Class 2: 0.7330476430552054\n",
            "Average Recall: 0.6541666666666667\n"
          ]
        }
      ],
      "source": [
        "recall_perceptron = recall_score(y_test, y_pred, average=None)\n",
        "if env == 'colab':\n",
        "  print(f'Recall for class 0: {recall_perceptron[0]} Class 1: {recall_perceptron[1]} Class 2: {recall_perceptron[2]}')\n",
        "recall_perceptron_avg = recall_score(y_test, y_pred, average='micro')\n",
        "if env == 'colab':\n",
        "  print(f'Average Recall: {recall_perceptron_avg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dQC0QCbYJTE"
      },
      "source": [
        "### F1 Score\n",
        "F1 combines precision and recall and gives a single metric to balance the two. It is the harmonic mean between precision and recall. \n",
        "\n",
        "An F1-score will be high when both the precision and recall are high, and will be low when either precision or recall is low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zAnU4F2IYi5t",
        "outputId": "5707bda9-70f2-4bfc-ed58-6463fc35293f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for class 0: 0.6899755501222494 Class 1: 0.5507208728406288 Class 2: 0.7161679596108853\n",
            "Average F1 Score: 0.6541666666666667\n"
          ]
        }
      ],
      "source": [
        "f1_perceptron = f1_score(y_test, y_pred, average=None)\n",
        "if env == 'colab':\n",
        "  print(f'F1 for class 0: {f1_perceptron[0]} Class 1: {f1_perceptron[1]} Class 2: {f1_perceptron[2]}')\n",
        "f1_perceptron_avg = f1_score(y_test, y_pred, average='micro')\n",
        "if env == 'colab':\n",
        "  print(f'Average F1 Score: {f1_perceptron_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "die2HzrUFiSz",
        "outputId": "9bad8df0-dddc-485a-ad26-1362353dc124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.674635429117858, 0.5787605787605787, 0.7000481463649495, 0.6541666666666667\n",
            "0.7060295221416062, 0.5252725470763132, 0.7330476430552054, 0.6541666666666667\n",
            "0.6899755501222494, 0.5507208728406288, 0.7161679596108853, 0.6541666666666667\n"
          ]
        }
      ],
      "source": [
        "print(f'{precision_perceptron[0]}, {precision_perceptron[1]}, {precision_perceptron[2]}, {precision_perceptron_avg}')\n",
        "print(f'{recall_perceptron[0]}, {recall_perceptron[1]}, {recall_perceptron[2]}, {recall_perceptron_avg}')\n",
        "print(f'{f1_perceptron[0]}, {f1_perceptron[1]}, {f1_perceptron[2]}, {f1_perceptron_avg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hq4c_0euGp9"
      },
      "source": [
        "# SVM\n",
        "An SVM finds the best boundary/hyperplane that seperates the data into seperate classees. This should maximize maximizes the margin, which is the distance between the boundary and the closest data points from each class, also called support vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yrloxe8HuGp9"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC(random_state=0, max_iter=1000).fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "PfX3TtEym0NF"
      },
      "outputs": [],
      "source": [
        "svm_pred = svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MY-AERDmAI8h",
        "outputId": "00b9d2e4-11e4-42b0-f124-7e7d7bd261f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for class 0: 0.7454723445912873 Class 1: 0.6180378129790496 Class 2: 0.7597499999999999\n"
          ]
        }
      ],
      "source": [
        "f1_svm = f1_score(y_test, svm_pred, average=None)\n",
        "if env == 'colab':\n",
        "  print(f'F1 for class 0: {f1_svm[0]} Class 1: {f1_svm[1]} Class 2: {f1_svm[2]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_xrHVYGdAF52",
        "outputId": "c795cffc-2ba0-4295-a390-40bc2e223e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 (Linear SVM):  70.73\n"
          ]
        }
      ],
      "source": [
        "svm_f1_avg = f1_score(y_test, svm_pred, average='weighted')\n",
        "if env == 'colab':\n",
        "  print('F1 (Linear SVM): ', \"%.2f\" % (svm_f1_avg*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rT2Fiq-B-XIF",
        "outputId": "ed90eb03-e3c5-4faa-8f0e-de8445ca6912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall for class 0: 0.7620715536652489 Class 1: 0.5993557978196233 Class 2: 0.7660700781446937\n",
            "Average Recall: 0.7086666666666667\n"
          ]
        }
      ],
      "source": [
        "recall_svm = recall_score(y_test, svm_pred, average=None)\n",
        "if env == 'colab':\n",
        "  print(f'Recall for class 0: {recall_svm[0]} Class 1: {recall_svm[1]} Class 2: {recall_svm[2]}')\n",
        "recall_svm_avg = recall_score(y_test, svm_pred, average='micro')\n",
        "if env == 'colab':\n",
        "  print(f'Average Recall: {recall_svm_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "buYFC0Zri6Ox",
        "outputId": "380a702a-7168-4d09-a5fc-626ef8dce8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision for class 0: 0.7295808383233533 Class 1: 0.63792194092827 Class 2: 0.7535333498636251\n",
            "Average Precision: 0.7086666666666667\n"
          ]
        }
      ],
      "source": [
        "precision_svm = precision_score(y_test, svm_pred, average=None)\n",
        "if env == 'colab':  \n",
        "  print(f'Precision for class 0: {precision_svm[0]} Class 1: {precision_svm[1]} Class 2: {precision_svm[2]}')\n",
        "precision_svm_avg = precision_score(y_test, svm_pred, average='micro')\n",
        "if env == 'colab':  \n",
        "  print(f'Average Precision: {precision_svm_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aE9h4M_0GuSr",
        "outputId": "60125f9c-e9ac-466e-cdba-21efbebfc003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7295808383233533, 0.63792194092827, 0.7535333498636251, 0.7086666666666667\n",
            "0.7620715536652489, 0.5993557978196233, 0.7660700781446937, 0.7086666666666667\n",
            "0.7454723445912873, 0.6180378129790496, 0.7597499999999999, 0.7073318187095682\n"
          ]
        }
      ],
      "source": [
        "print(f'{precision_svm[0]}, {precision_svm[1]}, {precision_svm[2]}, {precision_svm_avg}')\n",
        "print(f'{recall_svm[0]}, {recall_svm[1]}, {recall_svm[2]}, {recall_svm_avg}')\n",
        "print(f'{f1_svm[0]}, {f1_svm[1]}, {f1_svm[2]}, {svm_f1_avg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vedxkRgUuGp-"
      },
      "source": [
        "# Logistic Regression\n",
        "Multinomial logistic regression applies a linear function to a set of features and applies a softmax to the data to obtain a probability distribution over K classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LtkTriT5uGp-",
        "outputId": "907bd565-8af3-444b-8289-f5d053c5fd24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instantiate a logistic regression model\n",
        "logreg_clf = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
        "\n",
        "# Fit the model to the data\n",
        "logreg_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9BpcD92Gn8WT"
      },
      "outputs": [],
      "source": [
        "logreg_pred = logreg_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KdhllQRFoAJx",
        "outputId": "30be128e-c49c-4af1-80ad-ef509b40d2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision for class 0: 0.7470280551592963 Class 1: 0.6536312849162011 Class 2: 0.787603734439834\n",
            "Average Precision: 0.7294166666666667\n"
          ]
        }
      ],
      "source": [
        "precision_lr = precision_score(y_test, logreg_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'Precision for class 0: {precision_lr[0]} Class 1: {precision_lr[1]} Class 2: {precision_lr[2]}')\n",
        "precision_lr_avg = precision_score(y_test, logreg_pred, average='micro')\n",
        "if env == 'colab': \n",
        "  print(f'Average Precision: {precision_lr_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0XpyT_XZoOpO",
        "outputId": "aebe38ab-3d0b-41ef-afa6-ab1aafa87e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall for class 0: 0.7860895671753816 Class 1: 0.6377601585728444 Class 2: 0.7655659188303504\n",
            "Average Recall: 0.7294166666666667\n"
          ]
        }
      ],
      "source": [
        "recall_lr = recall_score(y_test, logreg_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'Recall for class 0: {recall_lr[0]} Class 1: {recall_lr[1]} Class 2: {recall_lr[2]}')\n",
        "recall_lr_avg = recall_score(y_test, logreg_pred, average='micro')\n",
        "if env == 'colab':  \n",
        "  print(f'Average Recall: {recall_lr_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PvHGy6TpoWDf",
        "outputId": "d0c0ba6b-74c3-4d04-be36-91a0b63a4ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for class 0: 0.7660611971230038 Class 1: 0.6455981941309256 Class 2: 0.776428480122715\n",
            "Average F1 Score: 0.7294166666666667\n"
          ]
        }
      ],
      "source": [
        "f1_lr = f1_score(y_test, logreg_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'F1 for class 0: {f1_lr[0]} Class 1: {f1_lr[1]} Class 2: {f1_lr[2]}')\n",
        "f1_avg_lr = f1_score(y_test, logreg_pred, average='micro')\n",
        "if env == 'colab': \n",
        "  print(f'Average F1 Score: {f1_avg_lr}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VHFk8MAdHd12",
        "outputId": "9b2d627e-dd0a-4bea-9dd4-4d42ce85e39c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7470280551592963, 0.6536312849162011, 0.787603734439834, 0.7294166666666667\n",
            "0.7860895671753816, 0.6377601585728444, 0.7655659188303504, 0.7294166666666667\n",
            "0.7660611971230038, 0.6455981941309256, 0.776428480122715, 0.7294166666666667\n"
          ]
        }
      ],
      "source": [
        "print(f'{precision_lr[0]}, {precision_lr[1]}, {precision_lr[2]}, {precision_lr_avg}')\n",
        "print(f'{recall_lr[0]}, {recall_lr[1]}, {recall_lr[2]}, {recall_lr_avg}')\n",
        "print(f'{f1_lr[0]}, {f1_lr[1]}, {f1_lr[2]}, {f1_avg_lr}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehjiyApVuGp-"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql2Ka1yAj6Hd"
      },
      "source": [
        "Uses the frequency of the words in a document to determine probability that the document belongs in a certain class.\n",
        "\n",
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wgX5IiQzuGp-",
        "outputId": "59fc4a23-b78a-4edb-ba82-80f51d474dae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Instantiate a NB model\n",
        "clf_nb = MultinomialNB()\n",
        "\n",
        "# Fit the model to the data\n",
        "clf_nb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "zdEZXdPZkn8G"
      },
      "outputs": [],
      "source": [
        "clf_nb_pred = clf_nb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Son6bdzxk2JO",
        "outputId": "0df7ef5b-7dc1-41d9-8ba8-013ef3e68a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision for class 0: 0.7645669291338583 Class 1: 0.6214899048503133 Class 2: 0.7693893326462252\n",
            "Average Precision: 0.71475\n"
          ]
        }
      ],
      "source": [
        "precision_nb = precision_score(y_test, clf_nb_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'Precision for class 0: {precision_nb[0]} Class 1: {precision_nb[1]} Class 2: {precision_nb[2]}')\n",
        "precision_nb_avg = precision_score(y_test, clf_nb_pred, average='micro')\n",
        "if env == 'colab':  \n",
        "  print(f'Average Precision: {precision_nb_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k4csHQeblBkD",
        "outputId": "40f25444-5fee-481f-cfc1-97bcde7d7674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall for class 0: 0.7287965974480861 Class 1: 0.6635282457879088 Class 2: 0.7527098563145954\n",
            "Average Recall: 0.71475\n"
          ]
        }
      ],
      "source": [
        "recall_nb = recall_score(y_test, clf_nb_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'Recall for class 0: {recall_nb[0]} Class 1: {recall_nb[1]} Class 2: {recall_nb[2]}')\n",
        "recall_nb_avg = recall_score(y_test, clf_nb_pred, average='micro')\n",
        "if env == 'colab': \n",
        "  print(f'Average Recall: {recall_nb_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KnoW593zlLS8",
        "outputId": "3ee26512-b2b7-4b57-d6ac-db3ef5162397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for class 0: 0.7462533623671065 Class 1: 0.641821449970042 Class 2: 0.7609582059123344\n",
            "Average F1 Score: 0.71475\n"
          ]
        }
      ],
      "source": [
        "f1_nb = f1_score(y_test, clf_nb_pred, average=None)\n",
        "if env == 'colab': \n",
        "  print(f'F1 for class 0: {f1_nb[0]} Class 1: {f1_nb[1]} Class 2: {f1_nb[2]}')\n",
        "f1_avg_nb = f1_score(y_test, clf_nb_pred, average='micro')\n",
        "if env == 'colab': \n",
        "  print(f'Average F1 Score: {f1_avg_nb}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rFmHMEfJIBtu",
        "outputId": "dd2f0ded-4722-4a30-cf19-e7ce2b2fb67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7645669291338583, 0.6214899048503133, 0.7693893326462252, 0.71475\n",
            "0.7287965974480861, 0.6635282457879088, 0.7527098563145954, 0.71475\n",
            "0.7462533623671065, 0.641821449970042, 0.7609582059123344, 0.71475\n"
          ]
        }
      ],
      "source": [
        "print(f'{precision_nb[0]}, {precision_nb[1]}, {precision_nb[2]}, {precision_nb_avg}')\n",
        "print(f'{recall_nb[0]}, {recall_nb[1]}, {recall_nb[2]}, {recall_nb_avg}')\n",
        "print(f'{f1_nb[0]}, {f1_nb[1]}, {f1_nb[2]}, {f1_avg_nb}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
